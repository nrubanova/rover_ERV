{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teTELR = '/D_mel_transposon_sequence_set.fa' # from https://github.com/bergmanlab/drosophila-transposons/blob/master/current/D_mel_transposon_sequence_set.fa\n",
    "\n",
    "def load_ref_te(teTELR):\n",
    "    tes = {}\n",
    "    tes_by_subfamily = {}\n",
    "    subfamily_order = {}\n",
    "    for seq_record in SeqIO.parse(teTELR, 'fasta'):\n",
    "        seqid = seq_record.id\n",
    "        ln = seqid.split('#')\n",
    "        subfamily = ln[0]\n",
    "        order = ln[1].split('/')[0]\n",
    "        superfamily = ln[1].split('/')[1]\n",
    "        if order not in tes:\n",
    "            tes[order] = {}\n",
    "        if superfamily not in tes[order]:\n",
    "            tes[order][superfamily] = {}\n",
    "\n",
    "        tes[order][superfamily][subfamily] = seq_record.seq\n",
    "        tes_by_subfamily[subfamily] = seq_record.seq\n",
    "        subfamily_order[subfamily] = order\n",
    "    ref_te_len = {}\n",
    "    for order in tes.keys():\n",
    "        for superfamily in tes[order]:\n",
    "            for subfamily in tes[order][superfamily]:            \n",
    "                ref_te_len[subfamily] = len(str(tes[order][superfamily][subfamily]))\n",
    "        \n",
    "    return tes, tes_by_subfamily, ref_te_len, subfamily_order\n",
    "\n",
    "tes, tes_by_subfamily, ref_te_len, subfamily_to_order = load_ref_te(teTELR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['PGFP_5d_guts_P2', 'PGFP_5d_heads_P2',  \n",
    "           'PGFP_5d_guts_P3', 'PGFP_5d_heads_P3', \n",
    "           'PGFP_25d_guts_P1', 'PGFP_25d_guts_P2', \n",
    "           'PGFP_25d_heads_P1', 'PGFP_25d_heads_P2', \n",
    "           'PGFP_50d_guts_P1', 'PGFP_50d_heads_P1',\n",
    "           'PGFP_50d_guts_P2', 'PGFP_50d_heads_P2'\n",
    "          ]\n",
    "\n",
    "samples_heads = ['PGFP_5d_heads_P2', 'PGFP_5d_heads_P3', \n",
    "                 'PGFP_25d_heads_P1', 'PGFP_25d_heads_P2', \n",
    "                 'PGFP_50d_heads_P1', 'PGFP_50d_heads_P2'\n",
    "                ]\n",
    "\n",
    "samples_guts = ['PGFP_5d_guts_P2', 'PGFP_5d_guts_P3', \n",
    "                'PGFP_25d_guts_P1', 'PGFP_25d_guts_P2', \n",
    "                'PGFP_50d_guts_P1', 'PGFP_50d_guts_P2'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('~/final_table.csv', sep='\\t', index_col=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = result[result['Genotype']=='Singleton']\n",
    "counts = {}\n",
    "countslong = []\n",
    "counts_guts = {}\n",
    "counts_guts_long = []\n",
    "counts_heads = {}\n",
    "counts_heads_long = []\n",
    "for subfamily in singletons:\n",
    "    counts[subfamily] = []\n",
    "    counts_heads[subfamily] = []\n",
    "    counts_guts[subfamily] = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        length = len(tmp[(tmp['Subfamily'] == subfamily) & (tmp.Sample.str.contains(sample)  ) ] )\n",
    "\n",
    "        counts[subfamily].append( length )\n",
    "        countslong.append([subfamily, sample, length])\n",
    "    for sample in samples_guts:\n",
    "        length = len(tmp[(tmp['Subfamily'] == subfamily) & (tmp.Sample.str.contains(sample)  ) ] )\n",
    "\n",
    "        counts_guts[subfamily].append(length)\n",
    "        counts_guts_long.append([subfamily, sample, length])\n",
    "    for sample in samples_heads:\n",
    "        length = len(tmp[(tmp['Subfamily'] == subfamily) & (tmp.Sample.str.contains(sample)  ) ] )\n",
    "\n",
    "        counts_heads[subfamily].append(length)\n",
    "        counts_heads_long.append([subfamily, sample, length])\n",
    "        \n",
    "countsdf = pd.DataFrame.from_dict(counts, orient='index')\n",
    "countsdf.columns = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_guts_long_df = pd.DataFrame(counts_guts_long)\n",
    "counts_guts_long_df.columns = ['Subfamily', 'Sample', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfamilies = ['rover', 'copia', 'springer', 'I-element', 'Bari1']\n",
    "tissue = 'guts'\n",
    "order = ['PGFP_5d_guts_P2','PGFP_5d_guts_P3', \n",
    "     'PGFP_25d_guts_P1','PGFP_25d_guts_P2',\n",
    "     'PGFP_50d_guts_P1','PGFP_50d_guts_P2']\n",
    "    \n",
    "for subfamily in subfamilies:\n",
    "    df = counts_guts_long_df[counts_guts_long_df['Subfamily'] == subfamily]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.to_csv('~/' + subfamily + '_' + tissue + '_raw_counts.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_read_cout_per_bin_from_awk(awk_file, outfile):\n",
    "    read_length_data = {}\n",
    "    with open(awk_file) as indata, \\\n",
    "        open(outfile, 'w') as outdata:\n",
    "        for i, record in enumerate(indata):\n",
    "            bn = int(record.split('\\t')[1]) // 1000\n",
    "            if bn not in read_length_data:\n",
    "                read_length_data[bn] = 0\n",
    "            read_length_data[bn] += 1\n",
    "        for bn in sorted(read_length_data):\n",
    "            outdata.write('\\t'.join([str(bn), str(read_length_data[bn])]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_length_data = {}\n",
    "read_length_data_long = []\n",
    "\n",
    "for sample in samples:\n",
    "    awk_file = '~/' + sample + '.porechop.sorted.flt.primary.mapped.awk.readlength' #line format: read_id \\t read_length\n",
    "    outfile = '~/' + sample + '.porechop.sorted.flt.primary.mapped.readlength'\n",
    "    write_read_cout_per_bin_from_awk(awk_file, outfile)\n",
    "    read_length_data[sample] = {}\n",
    "    with open(outfile) as indata:\n",
    "        for i, l in enumerate(indata):\n",
    "            ln = l.rstrip().split('\\t')\n",
    "            bn = int(ln[0])\n",
    "            count = int(ln[1])\n",
    "            read_length_data[sample][bn] = count\n",
    "            read_length_data_long.append([sample, bn, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cpm(counts_long, ref_te_length, read_length_data):\n",
    "    counts_long_norm = []\n",
    "    for entry in counts_long:\n",
    "        subfamily = entry[0]\n",
    "        if subfamily not in somatic:\n",
    "            continue\n",
    "        sample = entry[1]\n",
    "        count = int(entry[2])\n",
    "        te_length_bin = (ref_te_len[subfamily] * 3.5) // 1000 \n",
    "        sum_counts = 0\n",
    "        for bn in read_length_data[sample].keys():\n",
    "            if bn >= te_length_bin:\n",
    "                sum_counts += read_length_data[sample][bn]\n",
    "        normalized_count = count * 1000 / sum_counts\n",
    "        counts_long_norm.append([subfamily, sample, count, normalized_count])\n",
    "    return counts_long_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_guts_long_norm = normalize_cpm(counts_guts_long, ref_te_len, read_length_data)\n",
    "counts_guts_long_norm_df = pd.DataFrame(counts_guts_long_norm)\n",
    "counts_guts_long_norm_df.columns = ['Subfamily', 'Sample', 'Count', 'Normalized_count']\n",
    "counts_guts_long_norm_df.set_index('Sample', inplace=True)\n",
    "\n",
    "counts_guts_long_norm_df.to_csv('~/counts_guts_raw_norm.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
